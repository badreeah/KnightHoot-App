{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T1AOoHRt677F"},"outputs":[],"source":["# +code\n","#=====>0 تثبيت المكتبات الضرورية ---\n","!pip install transformers datasets torch scikit-learn nltk imbalanced-learn fastapi uvicorn -q\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31511,"status":"ok","timestamp":1757007159815,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"VEt0nABm7dZv","outputId":"2cfde014-579f-424d-837c-ca473508836f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["# +code\n","#====>1  استيراد المكتبات ---\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","import nltk\n","from nltk.corpus import stopwords\n","from imblearn.over_sampling import RandomOverSampler\n","\n","# تحميل stopwords العربية\n","nltk.download('stopwords')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1757002959174,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"jAIG-dgd7iUQ","outputId":"6b65256d-ec4c-4a2d-cca2-4cda59c4ec03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Merged Dataset:\n","                             text  label\n","0  لقد ربحت جائزة اضغط على الرابط      1\n","1     موعد اجتماعك غداً الساعة 10      0\n","2           ارسل معلوماتك البنكية      1\n","3           محاضرة اليوم الساعة 2      0\n","4              تحقق من رصيدك الآن      1\n","5              الاجتماع تم تأجيله      0\n","\n","Column Names: Index(['text', 'label'], dtype='object')\n","Labels distribution:\n"," label\n","1    3\n","0    3\n","Name: count, dtype: int64\n"]}],"source":["# +code\n","#====>1  استيراد المكتبات ---\n","import pandas as pd\n","\n","#====>2  إنشاء DataFrame لكل مصدر كمثال ---\n","# GitHub dataset\n","data_github = {\n","    'Message': [\"لقد ربحت جائزة اضغط على الرابط\", \"موعد اجتماعك غداً الساعة 10\"],\n","    'Category': [\"spam\", \"ham\"]\n","}\n","df_github = pd.DataFrame(data_github)\n","\n","# UCI dataset\n","data_uci = {\n","    'V1': [\"ارسل معلوماتك البنكية\", \"محاضرة اليوم الساعة 2\"],\n","    'V2': [\"spam\", \"ham\"]\n","}\n","df_uci = pd.DataFrame(data_uci)\n","\n","# Mendeley dataset\n","data_mendeley = {\n","\n","    'text_message': [\"تحقق من رصيدك الآن\", \"الاجتماع تم تأجيله\"],\n","    'class': [\"spam\", \"ham\"]\n","\n","}\n","df_mendeley = pd.DataFrame(data_mendeley)\n","\n","# ===> 3 إعادة تسمية الأعمدة لتكون موحدة ---\n","df_github.columns = ['text', 'label']\n","df_uci.columns = ['text', 'label']\n","df_mendeley.columns = ['text', 'label']\n","\n","#====>4  دمج كل البيانات ---\n","df_all = pd.concat([df_github, df_uci, df_mendeley], ignore_index=True)\n","\n","#====>5    تحويل التصنيفات إلى 0 و 1 ---\n","df_all['label'] = df_all['label'].map({'ham':0, 'spam':1})\n","\n","#====>6  التحقق النهائي ---\n","print(\"Merged Dataset:\")\n","print(df_all)\n","print(\"\\nColumn Names:\", df_all.columns)\n","print(\"Labels distribution:\\n\", df_all['label'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1757003134600,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"mTCIR4-c7_rF","outputId":"f48b3192-c0b6-401d-d1ee-825f7cdfe71e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import re\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","arabic_stopwords = set(stopwords.words('arabic'))\n","\n","def clean_text(text):\n","    text = str(text).lower()\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = re.sub(r'\\d+', '', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r'[إأآا]', 'ا', text)\n","    text = re.sub(r'[ًٌٍَُِّ]', '', text)\n","    text_tokens = [word for word in text.split() if word not in arabic_stopwords]\n","    return ' '.join(text_tokens)\n","\n","df_all['clean_text'] = df_all['text'].apply(clean_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81,"status":"ok","timestamp":1757003137351,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"5Lmeunve8H1l","outputId":"2e765a9a-8a61-4f86-86da-a090d5b0a5eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Feature columns: ['word_count', 'char_count', 'keyword_رابط', 'keyword_ربح', 'keyword_تحقق', 'keyword_مكافأة', 'keyword_ارسال']\n","                             text  label                  clean_text  \\\n","0  لقد ربحت جائزة اضغط على الرابط      1  لقد ربحت جائزة اضغط الرابط   \n","1     موعد اجتماعك غداً الساعة 10      0         موعد اجتماعك الساعة   \n","2           ارسل معلوماتك البنكية      1       ارسل معلوماتك البنكية   \n","3           محاضرة اليوم الساعة 2      0         محاضرة اليوم الساعة   \n","4              تحقق من رصيدك الآن      1             تحقق رصيدك الان   \n","\n","   word_count  char_count  keyword_رابط  keyword_ربح  keyword_تحقق  \\\n","0           5          26             1            1             0   \n","1           3          19             0            0             0   \n","2           3          21             0            0             0   \n","3           3          19             0            0             0   \n","4           3          15             0            0             1   \n","\n","   keyword_مكافأة  keyword_ارسال  \n","0               0              0  \n","1               0              0  \n","2               0              0  \n","3               0              0  \n","4               0              0  \n"]}],"source":["-# نتأكد أن العمود موجود ونتعامل مع أي قيم فارغة\n","df_all['clean_text'] = df_all['clean_text'].fillna(\"\").astype(str)\n","\n","# حساب عدد الكلمات والحروف\n","df_all['word_count'] = df_all['clean_text'].apply(lambda x: len(x.split()))\n","df_all['char_count'] = df_all['clean_text'].apply(lambda x: len(x))\n","\n","# الكلمات المفتاحية\n","keywords = ['رابط','ربح','تحقق','مكافأة','ارسال']\n","for kw in keywords:\n","    df_all[f'keyword_{kw}'] = df_all['clean_text'].apply(lambda x: x.count(kw))\n","\n","# الأعمدة المميزة\n","feature_cols = ['word_count', 'char_count'] + [f'keyword_{kw}' for kw in keywords]\n","\n","print(\"Feature columns:\", feature_cols)\n","print(df_all.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_r_-fK5T8Ki4"},"outputs":[],"source":["# +code\n","!pip install transformers torch --quiet\n","from transformers import AutoTokenizer\n","\n","model_name = \"aubmindlab/bert-base-arabertv02\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","encodings = tokenizer(df_all['clean_text'].tolist(), truncation=True, padding=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgRkQhYH9tcL","outputId":"b27f3c76-b7ed-471d-999b-af0d68cd6aca","executionInfo":{"status":"ok","timestamp":1757007204270,"user_tz":-180,"elapsed":26795,"user":{"displayName":"KH ́","userId":"05089605944381426737"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n","\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: fineGrained).\n","The token `khawlah` has been saved to /root/.cache/huggingface/stored_tokens\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful.\n","The current active token is: `khawlah`\n"]}],"source":["!huggingface-cli login\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":32,"status":"error","timestamp":1757007216087,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"HouWyVuU8OCI","outputId":"0951b113-d28f-46d6-b44b-ecb10b41bd08"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'encodings' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3363994554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset example:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'encodings' is not defined"]}],"source":["# +code\n","import torch\n","\n","class SMSDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __len__(self):\n","        return len(self.labels)\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","dataset = SMSDataset(encodings, df_all['label'].tolist())\n","print(\"Dataset example:\", dataset[0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpBBN0dK8cPn"},"outputs":[],"source":["# +code\n","!pip install scikit-learn --quiet\n","from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["537a277099074392af81b5026c74f94a","0572a366dfc34979a96963e750c3e2bd","c530e44864f5495d84b590c4014f149f","b8e414a93ca5497d8b06dab2b4b6f64d","13347d8efee2441a996736829c1c1c82","fd6636e9c5e1468b82522fe6f22d4d8b","ce45a58840044ccfad7cb1797a1954ee","1d719591942343feac5e25d8ca5b3258","6bc9ce6521c240adac8ac9f13876695c","c122f65a8230489fbab917c1a38d21a7","4521969ee5a34e8ca8cced3f414f0806"]},"executionInfo":{"elapsed":8413,"status":"ok","timestamp":1756842052176,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"UJGRUxWS8fIS","outputId":"14c73127-6e99-46e0-f74a-bb2104d994a4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"537a277099074392af81b5026c74f94a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# +code\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","\n","# ملاحظة: num_labels=2 لأننا نصنف الرسائل إلى spam أو ham\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xt0IPCTd8kkX"},"outputs":[],"source":["# +code\n","def compute_metrics(p):\n","    preds = p.predictions.argmax(-1)  # اختيار الفئة ذات أعلى احتمال\n","    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n","    acc = accuracy_score(p.label_ids, preds)\n","    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68233,"status":"ok","timestamp":1757003748335,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"TEv8tnBS8oBw","outputId":"a6a09af9-ac49-4f31-8bef-0d6883b12f33"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# +code\n","# تحديث مكتبة transformers\n","!pip install --upgrade transformers --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"083KFtr38r4-"},"outputs":[],"source":["# +code\n","from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",             # حفظ النموذج والlogs هنا\n","    num_train_epochs=3,                 # عدد الـ epochs\n","    per_device_train_batch_size=4,      # حجم الباتش أثناء التدريب\n","    per_device_eval_batch_size=4,       # حجم الباتش أثناء التقييم\n","    logging_dir=\"./logs\",               # مجلد حفظ السجلات\n","    logging_steps=10,                   # كل 10 خطوات تسجيل المعلومات\n","    learning_rate=5e-5,\n","    weight_decay=0.01\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":803,"status":"ok","timestamp":1757001154490,"user":{"displayName":"KH ́","userId":"05089605944381426737"},"user_tz":-180},"id":"ecQhgeur_kbA","outputId":"e5e133a3-b99e-4e39-f7a2-288a14b6c4b3"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# +code\n","from transformers import AutoModelForSequenceClassification\n","\n","# تحميل الموديل العربي BERT مع 2 فئة (spam / ham)\n","model_name = \"aubmindlab/bert-base-arabertv02\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"]},{"cell_type":"code","source":["# +code\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","\n","# ==== تقسيم البيانات إلى train و test ====\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df_all['clean_text'].tolist(),   # النصوص\n","    df_all['label'].tolist(),        # التصنيفات\n","    test_size=0.2,                   # 20% للاختبار\n","    random_state=42,\n","    stratify=df_all['label']         # يحافظ على نسبة spam/ham\n",")\n","\n","# ==== تحويل النصوص للترميزات باستخدام tokenizer ====\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n","\n","# ==== إنشاء Dataset لكل مجموعة ====\n","train_dataset = SpamDataset(train_encodings, train_labels)\n","test_dataset = SpamDataset(test_encodings, test_labels)\n","\n","# ==== إنشاء DataLoader لكل مجموعة ====\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","\n","print(\"Train/Test datasets and DataLoaders are ready!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-w-kdDuZkaMK","executionInfo":{"status":"ok","timestamp":1757003514651,"user_tz":-180,"elapsed":49,"user":{"displayName":"KH ́","userId":"05089605944381426737"}},"outputId":"77a45c53-f356-41b8-bc98-730fefe15c30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train/Test datasets and DataLoaders are ready!\n"]}]},{"cell_type":"code","source":["# +code\n","import torch\n","from torch import nn\n","from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# ==== تجهيز الجهاز (GPU إذا موجود) ====\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","print(\"Using device:\", device)\n","\n","# ==== إعداد optimizer ====\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# ==== عدد epochs ====\n","epochs = 3\n","\n","# ==== Training Loop ====\n","for epoch in range(epochs):\n","    model.train()  # وضع الموديل في وضع التدريب\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","\n","        # نقل البيانات للجهاز (GPU/CPU)\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # تمرير البيانات للموديل\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        # backward + update\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # ==== Evaluation بعد كل epoch ====\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            preds = torch.argmax(logits, dim=1)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # ==== حساب Metrics ====\n","    acc = accuracy_score(all_labels, all_preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n","\n","    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Test Acc: {acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FvqhFYeluF_","executionInfo":{"status":"ok","timestamp":1757003858358,"user_tz":-180,"elapsed":19319,"user":{"displayName":"KH ́","userId":"05089605944381426737"}},"outputId":"f70ad22e-1db9-44b8-a698-bc960dadfe8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 | Train Loss: 0.7728 | Test Acc: 0.5000 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 | Train Loss: 0.4504 | Test Acc: 0.5000 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n","Epoch 3/3 | Train Loss: 0.3485 | Test Acc: 0.5000 | Precision: 0.5000 | Recall: 1.0000 | F1: 0.6667\n"]}]},{"cell_type":"code","source":["# Evaluation نهائي على Test Set\n","model.eval()\n","all_preds = []\n","all_probs = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        probs = torch.softmax(outputs.logits, dim=1)  # احتمالات لكل فئة\n","        preds = torch.argmax(probs, dim=1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_probs.extend(probs.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# حساب Metrics\n","acc = accuracy_score(all_labels, all_preds)\n","precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n","\n","print(\"=== Final Test Metrics ===\")\n","print(f\"Accuracy: {acc:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1-score: {f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"iZgoLZlimYPp","executionInfo":{"status":"error","timestamp":1757004937245,"user_tz":-180,"elapsed":82,"user":{"displayName":"KH ́","userId":"05089605944381426737"}},"outputId":"00c82572-b327-4f87-bb03-1ee46a734384"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1981505026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluation نهائي على Test Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["# +code\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","import torch\n","\n","# ==== تهيئة التطبيق ====\n","app = FastAPI()\n","\n","# ==== موديل + tokenizer جاهز ====\n","model.eval()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","# ==== نموذج البيانات ====\n","class Message(BaseModel):\n","    text: str\n","\n","# ==== دالة التنبؤ ====\n","def predict_message(text):\n","    encoding = tokenizer([text], truncation=True, padding=True, return_tensors=\"pt\")\n","    encoding = {key: val.to(device) for key, val in encoding.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**encoding)\n","        probs = torch.softmax(outputs.logits, dim=1)\n","        pred_class = torch.argmax(probs, dim=1).item()\n","        confidence = probs[0][pred_class].item()\n","\n","    if confidence < 0.6:   # أي رسالة غير واضحة\n","        result = \"This message is suspected to be a scam.\"\n","    else:\n","        result = \"spam\" if pred_class == 1 else \"Not spam\"\n","\n","    return {\"classification\": result, \"confidence\": round(confidence*100, 2)}\n","\n","# ==== إنشاء endpoint ====\n","@app.post(\"/predict/\")\n","def predict(message: Message):\n","    return predict_message(message.text)\n"],"metadata":{"id":"i4j_gcdgmm6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# تثبيت ngrok لتشغيل API على Colab\n","!pip install pyngrok -q\n","from pyngrok import ngrok\n"],"metadata":{"id":"H3ISaFe3mx4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# تشغيل FastAPI\n","!pip install fastapi uvicorn -q\n","\n","# استدعاء كود FastAPI\n","# تأكد أن الكود يحتوي:\n","# - تعريف app = FastAPI()\n","# - predict_message() + class Message(BaseModel)\n","# - endpoint /predict/\n"],"metadata":{"id":"BrhlbMWCm6GP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# +code\n","import nest_asyncio\n","import uvicorn\n","from pyngrok import ngrok\n","\n","# السماح بتشغيل uvicorn داخل Colab\n","nest_asyncio.apply()\n","\n","# ==== تفعيل authtoken الخاص بالجهاز  على ngrok ====\n","!ngrok authtoken \"32F779cdExdXmngnDlzZuL3NB9Y_68Mntay3q8nL5D35VPCSX\"  #   token الخاص بك\n","\n","# فتح تونل ngrok على المنفذ 8000\n","public_url = ngrok.connect(addr=\"8000\", proto=\"http\")\n","print(\"Public URL:\", public_url)\n","\n","# تشغيل Uvicorn لخادم FastAPI\n","uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"],"metadata":{"id":"kJrqOJIDqf53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["{\n","  \"text\": \"تحقق من رصيدك الآن!\",\n","  \"classification\": \"spam\",\n","  \"confidence\": 92.5\n","}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3TI12dWKqn9Q","executionInfo":{"status":"ok","timestamp":1757005315826,"user_tz":-180,"elapsed":32,"user":{"displayName":"KH ́","userId":"05089605944381426737"}},"outputId":"1b2f9dd2-093d-4e34-f67d-9ae8e370d0ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': 'تحقق من رصيدك الآن!', 'classification': 'spam', 'confidence': 92.5}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import psycopg2\n","import json\n","from datetime import datetime\n","\n","DB_CONFIG = {\n","    \"dbname\": \"postgres\",           # اسم قاعدة البيانات\n","    \"user\": \"postgres\",             # اسم المستخدم الافتراضي\n","    \"password\": \"https://qsgrxnzljtoebmeqcpbp.supabase.co\",\n","    \"host\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFzZ3J4bnpsanRvZWJtZXFjcGJwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTg2MzQ1MTMsImV4cCI6MjA3NDIxMDUxM30.2sHDLxRF_dZp0tbZ5_Pefed3rsOoEfw5zMVAjEjIqZs\"\n","}\n","\n","def log_sms_scan_result(sender_id: str, message_content: str, classification: str, score: float, details: dict):\n","    \"\"\"\n","    تسجل نتيجة فحص الرسالة النصية في جدول sms_safe_scans.\n","    \"\"\"\n","    conn = None\n","    try:\n","        # 1. الاتصال بقاعدة البيانات\n","        conn = psycopg2.connect(**DB_CONFIG)\n","        cursor = conn.cursor()\n","\n","        # 2. تحويل التفاصيل إلى JSON String للتخزين في حقل TEXT/JSONB\n","        details_json = json.dumps(details)\n","\n","        # 3. بناء استعلام الإدخال (INSERT)\n","        insert_query = \"\"\"\n","        INSERT INTO public.sms_safe_scans (\n","            sender_id,\n","            message_content,\n","            type,                     -- سنفترض أنه 'ML_Classification' مؤقتاً\n","            classification_response,\n","            score,\n","            details\n","        ) VALUES (%s, %s, %s, %s, %s, %s);\n","        \"\"\"\n","\n","        # 4. تنفيذ الاستعلام\n","        cursor.execute(insert_query, (\n","            sender_id,\n","            message_content,\n","            'ML_Classification',\n","            classification,\n","            score,\n","            details_json\n","        ))\n","\n","        # 5. تأكيد التغييرات\n","        conn.commit()\n","        print(\"Scan result logged successfully.\")\n","\n","    except (Exception, psycopg2.Error) as error:\n","        print(f\"Error while connecting to PostgreSQL or logging data: {error}\")\n","    finally:\n","        # 6. إغلاق الاتصال\n","        if conn:\n","            cursor.close()\n","            conn.close()"],"metadata":{"id":"-So1IH21Wz6H","executionInfo":{"status":"ok","timestamp":1763996448328,"user_tz":-180,"elapsed":1407,"user":{"displayName":"KH ́","userId":"05089605944381426737"}}},"execution_count":3,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1wgbdAItQkG847qZnWmKR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0572a366dfc34979a96963e750c3e2bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6636e9c5e1468b82522fe6f22d4d8b","placeholder":"​","style":"IPY_MODEL_ce45a58840044ccfad7cb1797a1954ee","value":"model.safetensors: 100%"}},"13347d8efee2441a996736829c1c1c82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d719591942343feac5e25d8ca5b3258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4521969ee5a34e8ca8cced3f414f0806":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"537a277099074392af81b5026c74f94a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0572a366dfc34979a96963e750c3e2bd","IPY_MODEL_c530e44864f5495d84b590c4014f149f","IPY_MODEL_b8e414a93ca5497d8b06dab2b4b6f64d"],"layout":"IPY_MODEL_13347d8efee2441a996736829c1c1c82"}},"6bc9ce6521c240adac8ac9f13876695c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8e414a93ca5497d8b06dab2b4b6f64d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c122f65a8230489fbab917c1a38d21a7","placeholder":"​","style":"IPY_MODEL_4521969ee5a34e8ca8cced3f414f0806","value":" 543M/543M [00:07&lt;00:00, 85.0MB/s]"}},"c122f65a8230489fbab917c1a38d21a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c530e44864f5495d84b590c4014f149f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d719591942343feac5e25d8ca5b3258","max":543432324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bc9ce6521c240adac8ac9f13876695c","value":543432324}},"ce45a58840044ccfad7cb1797a1954ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd6636e9c5e1468b82522fe6f22d4d8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}